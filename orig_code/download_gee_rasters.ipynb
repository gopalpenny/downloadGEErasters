{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3a8f244-d303-47b2-87f6-19c95c789685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import geemap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ee\n",
    "import re\n",
    "import plotnine as p9\n",
    "import sys\n",
    "from datetime import timedelta\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "483459ab-15d1-4e36-b855-9421a47679df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c103798-e267-4298-88c8-45819f17303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shp_name = \"SquareBuffer1km\"\n",
    "shp_dir = \"UbonRatchathani\"\n",
    "sq1km = gpd.read_file(os.path.join(shp_dir, shp_name + \".shp\"))\n",
    "sq1km_ee = geemap.geopandas_to_ee(sq1km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3f7daf6-4cc2-4ba1-8fcc-28bcf55a2f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_drive_path = '/Users/gopal/Google Drive/_Research/Research projects/ML/downloadsentinel'\n",
    "shp_gdrive_path = os.path.join(google_drive_path,shp_name)\n",
    "shp_gee_folder_name = shp_name + '_GEE'\n",
    "shp_gee_folder_path = os.path.join(shp_gdrive_path, shp_gee_folder_name)\n",
    "\n",
    "if not os.path.exists(shp_gdrive_path):\n",
    "    os.mkdir(shp_gdrive_path)\n",
    "if not os.path.exists(shp_gee_folder_path):\n",
    "    os.mkdir(shp_gee_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fe86c3e4-f94a-45ea-8def-af9bc3c3e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.addLayer(sq1km_ee,{},'sq1km_ee')\n",
    "Map.centerObject(sq1km_ee, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acf59446-56c9-4215-82d9-766e349509b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = ee.ImageCollection(\"COPERNICUS/S1_GRD\") \\\n",
    "  .filterBounds(sq1km_ee) #\\\n",
    "  # .filterDate(\"2020-01-01\",\"2020-02-01\")\n",
    "# s1.size().getInfo()\n",
    "s1_image_names = s1.aggregate_array(\"system:index\").getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00ec912b-4c29-4578-981a-46c00cfb309f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe43c0f6-d3ef-4184-8362-b0cfd5dd66db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>datestr</th>\n",
       "      <th>date</th>\n",
       "      <th>days_until_next</th>\n",
       "      <th>doy</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20150304T225147_20150304T2252...</td>\n",
       "      <td>20150304</td>\n",
       "      <td>2015-03-04</td>\n",
       "      <td>24.0</td>\n",
       "      <td>63</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20150328T225148_20150328T2252...</td>\n",
       "      <td>20150328</td>\n",
       "      <td>2015-03-28</td>\n",
       "      <td>24.0</td>\n",
       "      <td>87</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20150421T225148_20150421T2252...</td>\n",
       "      <td>20150421</td>\n",
       "      <td>2015-04-21</td>\n",
       "      <td>48.0</td>\n",
       "      <td>111</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20150608T225154_20150608T2252...</td>\n",
       "      <td>20150608</td>\n",
       "      <td>2015-06-08</td>\n",
       "      <td>24.0</td>\n",
       "      <td>159</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20150702T225157_20150702T2252...</td>\n",
       "      <td>20150702</td>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>48.0</td>\n",
       "      <td>183</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20221216T225252_20221216T2253...</td>\n",
       "      <td>20221216</td>\n",
       "      <td>2022-12-16</td>\n",
       "      <td>8.0</td>\n",
       "      <td>350</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20221224T111302_20221224T1113...</td>\n",
       "      <td>20221224</td>\n",
       "      <td>2022-12-24</td>\n",
       "      <td>4.0</td>\n",
       "      <td>358</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20221228T225251_20221228T2253...</td>\n",
       "      <td>20221228</td>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>8.0</td>\n",
       "      <td>362</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20230105T111301_20230105T1113...</td>\n",
       "      <td>20230105</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20230109T225251_20230109T2253...</td>\n",
       "      <td>20230109</td>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>575 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 names   datestr       date  \\\n",
       "0    S1A_IW_GRDH_1SDV_20150304T225147_20150304T2252...  20150304 2015-03-04   \n",
       "1    S1A_IW_GRDH_1SDV_20150328T225148_20150328T2252...  20150328 2015-03-28   \n",
       "2    S1A_IW_GRDH_1SDV_20150421T225148_20150421T2252...  20150421 2015-04-21   \n",
       "3    S1A_IW_GRDH_1SDV_20150608T225154_20150608T2252...  20150608 2015-06-08   \n",
       "4    S1A_IW_GRDH_1SDV_20150702T225157_20150702T2252...  20150702 2015-07-02   \n",
       "..                                                 ...       ...        ...   \n",
       "392  S1A_IW_GRDH_1SDV_20221216T225252_20221216T2253...  20221216 2022-12-16   \n",
       "393  S1A_IW_GRDH_1SDV_20221224T111302_20221224T1113...  20221224 2022-12-24   \n",
       "394  S1A_IW_GRDH_1SDV_20221228T225251_20221228T2253...  20221228 2022-12-28   \n",
       "395  S1A_IW_GRDH_1SDV_20230105T111301_20230105T1113...  20230105 2023-01-05   \n",
       "396  S1A_IW_GRDH_1SDV_20230109T225251_20230109T2253...  20230109 2023-01-09   \n",
       "\n",
       "     days_until_next  doy  year  \n",
       "0               24.0   63  2015  \n",
       "1               24.0   87  2015  \n",
       "2               48.0  111  2015  \n",
       "3               24.0  159  2015  \n",
       "4               48.0  183  2015  \n",
       "..               ...  ...   ...  \n",
       "392              8.0  350  2022  \n",
       "393              4.0  358  2022  \n",
       "394              8.0  362  2022  \n",
       "395              4.0    5  2023  \n",
       "396              NaN    9  2023  \n",
       "\n",
       "[575 rows x 6 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_table = pd.DataFrame({'names' : s1_image_names})\n",
    "s1_table['datestr'] = [re.sub(\".*_.*_.*_.*_([0-9]+)T[0-9]+_.*\",\"\\\\1\",x) for x in s1_table[\"names\"]]\n",
    "s1_table['date'] = pd.to_datetime(s1_table['datestr'], format = \"%Y%m%d\")\n",
    "s1_table = s1_table.sort_values('date')\n",
    "\n",
    "# s1_table['day_diff'] = 1\n",
    "# print(np.array(s1_table.loc[1:2,'date']))\n",
    "# print(np.array(s1_table.loc[0:1,'date']))\n",
    "# print(s1_table['date'].shift(0))\n",
    "s1_table['days_until_next'] = (s1_table['date'].shift(-1) - s1_table['date']).dt.days\n",
    "\n",
    "# np.array(s1_table.loc[1:2,'date']) - np.array(s1_table.loc[0:1,'date'])\n",
    "s1_table['doy'] = [int(datetime.strftime(x, '%j')) for x in s1_table['date']]\n",
    "s1_table['year'] = [int(datetime.strftime(x, '%Y')) for x in s1_table['date']]\n",
    "s1_table\n",
    "# s1_tablep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a1602cbd-48d3-4c6b-b09b-8314c0e877a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 575\n",
      "Number of selected images: 403\n"
     ]
    }
   ],
   "source": [
    "doy_select = np.arange(1, 370, 6)\n",
    "\n",
    "\n",
    "def resample_nearest_days(doy_select, days_orig):\n",
    "    \"\"\"\n",
    "    This function returns an np array, days_nearest, which reflects the unique\n",
    "    values of days_orig that are closest to each value of doy_select\n",
    "    doy_select: np.array\n",
    "    days_orig: np.array\n",
    "    \"\"\"\n",
    "    doy_select_mat = np.expand_dims(days_orig, 0).repeat(len(doy_select), 0)\n",
    "    days_orig_mat = np.expand_dims(doy_select, 1).repeat(len(days_orig), 1)\n",
    "    doy_nearest_idx = np.argmin(np.abs(days_orig_mat - doy_select_mat),axis = 1)\n",
    "    days_nearest = days_orig[np.unique(doy_nearest_idx)]\n",
    "    return days_nearest\n",
    "\n",
    "\n",
    "# get names in each year\n",
    "resample_names = []\n",
    "for year in pd.unique(s1_table['year']):\n",
    "    # year = 2016\n",
    "    days_orig = np.array(s1_table[s1_table['year'] == year]['doy'])\n",
    "    days_resampled = resample_nearest_days(doy_select, days_orig)\n",
    "    # days_resampled.shape\n",
    "    s1_im_year = s1_table[s1_table['year'] == year]\n",
    "    # s1_im_year = s1_im_year[~s1_im_year['doy'].duplicated()]\n",
    "    s1_im_year_resampled_names = s1_im_year.names[\n",
    "        (s1_table['doy'].isin(days_resampled)) &\n",
    "        (~s1_im_year['doy'].duplicated())]\n",
    "    resample_names = resample_names + s1_im_year_resampled_names.values.tolist()\n",
    "\n",
    "\n",
    "s1_table['sample'] = s1_table['names'].isin(resample_names)\n",
    "s1_table['downloaded'] = 1\n",
    "s1_table['gee_task_sent'] = \"\"\n",
    "# s1_table[s1_table['year'] == 2018]\n",
    "\n",
    "print(\"Total number of images:\",s1_table.shape[0])\n",
    "print(\"Number of selected images:\",np.sum(s1_table['sample'].values))\n",
    "\n",
    "s1_table_path = os.path.join(shp_gdrive_path, 's1_table.csv')\n",
    "\n",
    "s1_table.to_csv(s1_table_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7daefda4-f738-42db-a16a-03dc44940d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S1A_IW_GRDH_1SDV_20150702T225157_20150702T225222_006638_008DBE_4A71'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "26557496-bb1c-45da-8eef-c73eaaf30870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'downloaded'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_name = s1_table.names.values[12]\n",
    "def check_s1_table_image(s1_table_path, im_name):\n",
    "    # check if we can download file\n",
    "\n",
    "    # 1 read s1_table\n",
    "    s1_table = pd.read_csv(s1_table_path, keep_default_na = False)\n",
    "\n",
    "    # 2 subset to image\n",
    "    s1_table_im = s1_table[s1_table['names'] == im_name]\n",
    "    downloaded = s1_table_im.downloaded.values.item()\n",
    "    gee_task_sent = s1_table_im.gee_task_sent.values.item()\n",
    "    # 3 return status as \"gee_task_sent\", \"downloaded\", or \"not_downloaded\"\n",
    "    if downloaded:\n",
    "        im_status = 'downloaded'\n",
    "    elif not gee_task_sent == '':\n",
    "        im_status = 'gee_task_sent'\n",
    "    else:\n",
    "        im_status = 'not_downloaded'\n",
    "\n",
    "    return im_status\n",
    "\n",
    "foo = check_s1_table_image(s1_table_path, im_name)\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6a79998a-519f-44fe-9bed-4d578c27fb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(s1_table.gee_task_sent.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4bcb4a56-b2ee-4fe0-8eaa-5221839d66a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>datestr</th>\n",
       "      <th>date</th>\n",
       "      <th>days_until_next</th>\n",
       "      <th>doy</th>\n",
       "      <th>year</th>\n",
       "      <th>sample</th>\n",
       "      <th>downloaded</th>\n",
       "      <th>gee_task_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20160227T225153_20160227T2252...</td>\n",
       "      <td>20160227</td>\n",
       "      <td>2016-02-27</td>\n",
       "      <td>12.0</td>\n",
       "      <td>58</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-01-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                names   datestr        date  \\\n",
       "19  S1A_IW_GRDH_1SDV_20160227T225153_20160227T2252...  20160227  2016-02-27   \n",
       "\n",
       "    days_until_next  doy  year  sample  downloaded gee_task_sent  \n",
       "19             12.0   58  2016    True        True    2023-01-15  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update_s1_table_gee_task_sent\n",
    "\n",
    "def update_s1_table_gee_task_sent(s1_table_path, im_name, val):\n",
    "    # update specific image in s1_table with val\n",
    "    # 1 read s1_table\n",
    "    s1_table = pd.read_csv(s1_table_path)\n",
    "\n",
    "    # 2 insert val to talbe\n",
    "    s1_table.loc[s1_table['names'] == im_name, 'gee_task_sent'] = val\n",
    "    \n",
    "    s1_table.to_csv(s1_table_path, index = False)\n",
    "\n",
    "    return s1_table\n",
    "\n",
    "\n",
    "s1_table = update_s1_table_gee_task_sent(s1_table_path, im_name, val)\n",
    "\n",
    "s1_table[s1_table['names'] == im_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bd0724c0-29d7-492b-b2f7-89dd1dd53823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>datestr</th>\n",
       "      <th>date</th>\n",
       "      <th>days_until_next</th>\n",
       "      <th>doy</th>\n",
       "      <th>year</th>\n",
       "      <th>sample</th>\n",
       "      <th>downloaded</th>\n",
       "      <th>gee_task_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20150304T225147_20150304T2252...</td>\n",
       "      <td>20150304</td>\n",
       "      <td>2015-03-04</td>\n",
       "      <td>24.0</td>\n",
       "      <td>63</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20150328T225148_20150328T2252...</td>\n",
       "      <td>20150328</td>\n",
       "      <td>2015-03-28</td>\n",
       "      <td>24.0</td>\n",
       "      <td>87</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20150421T225148_20150421T2252...</td>\n",
       "      <td>20150421</td>\n",
       "      <td>2015-04-21</td>\n",
       "      <td>48.0</td>\n",
       "      <td>111</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20150608T225154_20150608T2252...</td>\n",
       "      <td>20150608</td>\n",
       "      <td>2015-06-08</td>\n",
       "      <td>24.0</td>\n",
       "      <td>159</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20150702T225157_20150702T2252...</td>\n",
       "      <td>20150702</td>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>48.0</td>\n",
       "      <td>183</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20221216T225252_20221216T2253...</td>\n",
       "      <td>20221216</td>\n",
       "      <td>2022-12-16</td>\n",
       "      <td>8.0</td>\n",
       "      <td>350</td>\n",
       "      <td>2022</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20221224T111302_20221224T1113...</td>\n",
       "      <td>20221224</td>\n",
       "      <td>2022-12-24</td>\n",
       "      <td>4.0</td>\n",
       "      <td>358</td>\n",
       "      <td>2022</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20221228T225251_20221228T2253...</td>\n",
       "      <td>20221228</td>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>8.0</td>\n",
       "      <td>362</td>\n",
       "      <td>2022</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20230105T111301_20230105T1113...</td>\n",
       "      <td>20230105</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>S1A_IW_GRDH_1SDV_20230109T225251_20230109T2253...</td>\n",
       "      <td>20230109</td>\n",
       "      <td>2023-01-09</td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>2023</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>575 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 names   datestr        date  \\\n",
       "0    S1A_IW_GRDH_1SDV_20150304T225147_20150304T2252...  20150304  2015-03-04   \n",
       "1    S1A_IW_GRDH_1SDV_20150328T225148_20150328T2252...  20150328  2015-03-28   \n",
       "2    S1A_IW_GRDH_1SDV_20150421T225148_20150421T2252...  20150421  2015-04-21   \n",
       "3    S1A_IW_GRDH_1SDV_20150608T225154_20150608T2252...  20150608  2015-06-08   \n",
       "4    S1A_IW_GRDH_1SDV_20150702T225157_20150702T2252...  20150702  2015-07-02   \n",
       "..                                                 ...       ...         ...   \n",
       "570  S1A_IW_GRDH_1SDV_20221216T225252_20221216T2253...  20221216  2022-12-16   \n",
       "571  S1A_IW_GRDH_1SDV_20221224T111302_20221224T1113...  20221224  2022-12-24   \n",
       "572  S1A_IW_GRDH_1SDV_20221228T225251_20221228T2253...  20221228  2022-12-28   \n",
       "573  S1A_IW_GRDH_1SDV_20230105T111301_20230105T1113...  20230105  2023-01-05   \n",
       "574  S1A_IW_GRDH_1SDV_20230109T225251_20230109T2253...  20230109  2023-01-09   \n",
       "\n",
       "    days_until_next  doy  year  sample  downloaded gee_task_sent  \n",
       "0              24.0   63  2015    True        True                \n",
       "1              24.0   87  2015    True        True    2023-01-15  \n",
       "2              48.0  111  2015    True        True    2023-01-15  \n",
       "3              24.0  159  2015    True        True    2023-01-15  \n",
       "4              48.0  183  2015    True        True    2023-01-15  \n",
       "..              ...  ...   ...     ...         ...           ...  \n",
       "570             8.0  350  2022    True       False                \n",
       "571             4.0  358  2022    True       False                \n",
       "572             8.0  362  2022    True       False                \n",
       "573             4.0    5  2023    True       False                \n",
       "574                    9  2023    True       False                \n",
       "\n",
       "[575 rows x 9 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_s1_table_all(s1_table_path):\n",
    "    # check all downloaded files\n",
    "\n",
    "    # 1 read s1_table\n",
    "    s1_table = pd.read_csv(s1_table_path, keep_default_na = False)\n",
    "    \n",
    "    # 2 check/updated all downloaded files\n",
    "    images_downloaded = [re.sub(\"\\\\.tif$\",\"\",x) for x in os.listdir(shp_gee_folder_path)]\n",
    "\n",
    "    s1_table['downloaded'] = s1_table['names'].isin(images_downloaded)\n",
    "    s1_table.to_csv(s1_table_path, index = False)\n",
    "    \n",
    "    return s1_table\n",
    "\n",
    "s1_table = update_s1_table_all(s1_table_path)\n",
    "s1_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "093bcd2a-8459-4bfc-a1f7-5b5fd4e8ed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_shp_s1(s1, shp_name, im_name, ee_geometry, shp_gee_folder_name, s1_table_path):\n",
    "    \n",
    "    im_status = check_s1_table_image(s1_table_path, im_name)\n",
    "    \n",
    "    if im_status == \"not_downloaded\":\n",
    "        s1_im_ic = s1.filterMetadata('system:index','equals',im_name)\n",
    "        assert s1_im_ic.size().getInfo() == 1\n",
    "        s1_im = s1_im_ic.first()\n",
    "        s1_im_shp_name = im_name + '_' + shp_name\n",
    "\n",
    "        print(f'Sending {shp_name}/{im_name} to GEE')\n",
    "        task = ee.batch.Export.image.toDrive(\n",
    "            image = s1_im.float(),\n",
    "            description = s1_im_shp_name,\n",
    "            folder = shp_gee_folder_name,\n",
    "            fileNamePrefix = im_name,\n",
    "            region = ee_geometry,\n",
    "            scale = 10,\n",
    "            maxPixels = 1000000,\n",
    "            fileFormat = 'GeoTIFF')\n",
    "        task.start()\n",
    "        \n",
    "        val = datetime.strftime(datetime.today(), \"%Y-%m-%d\")\n",
    "        update_s1_table_gee_task_sent(s1_table_path, im_name, val)\n",
    "        \n",
    "    else:\n",
    "        print(f'Image {shp_name}/{im_name} skipped, due to status: {im_status}')\n",
    "    \n",
    "    return 1\n",
    "\n",
    "\n",
    "# s1_im.double().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fd7c7a07-af5b-4428-95b4-0d40744d4099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image SquareBuffer1km/S1A_IW_GRDH_1SDV_20160227T225153_20160227T225218_010138_00EF3C_0DD6 skipped, due to status: downloaded\n",
      "Image SquareBuffer1km/S1A_IW_GRDH_1SDV_20160310T225153_20160310T225218_010313_00F43F_6E04 skipped, due to status: gee_task_sent\n",
      "Image SquareBuffer1km/S1A_IW_GRDH_1SDV_20160322T225154_20160322T225219_010488_00F925_04CA skipped, due to status: gee_task_sent\n",
      "Image SquareBuffer1km/S1A_IW_GRDH_1SDV_20160403T225208_20160403T225233_010663_00FE38_9DC4 skipped, due to status: gee_task_sent\n"
     ]
    }
   ],
   "source": [
    "for im_name in s1_table.names.values[19:23]:\n",
    "    download_shp_s1(s1, shp_name, im_name, ee_geometry, shp_gee_folder_name, s1_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e7b3b6af-7e1e-4e7f-b959-53574bb3a567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-01-15'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "62dfc950-bd72-42f2-8473-49da4078ae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "for im_name in s1_table.names.values[1:20]:\n",
    "    val = datetime.strftime(datetime.today(), \"%Y-%m-%d\")\n",
    "    update_s1_table_gee_task_sent(s1_table_path, im_name, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9661e14f-8634-445d-8771-1ddf83bd53b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee_ops = ee.data.listOperations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29155e96-f3f8-4235-8710-48079e5f361b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import json\n",
    "# type(ee_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbf1a76e-4cfa-4d39-8842-7469761f5a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending SquareBuffer1km/S1A_IW_GRDH_1SDV_20150702T225157_20150702T225222_006638_008DBE_4A71 to GEE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_name = s1_table.names[s1_table['sample']].values[4]\n",
    "ee_geometry = sq1km_ee.first().geometry()\n",
    "\n",
    "download_shp_s1(s1, shp_name, im_name, ee_geometry, shp_gee_folder_name, s1_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85574945-70b4-4f0e-b1f1-fcbf5f9290ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_gdrive_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a323a-6c47-426d-8644-1f66b42b38d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# download_path = os.path.join(google_drive_path, 's1_tiles_download')\n",
    "# def check_s1_image_status(shp_gdrive_path, shp_gee_folder_name):\n",
    "s1_table = pd.read_csv(s1_table_path)\n",
    "images_downloaded = [re.sub(\"\\\\.tif$\",\"\",x) for x in os.listdir(shp_gee_folder_path)]\n",
    "\n",
    "s1_table['downloaded'] = s1_table['names'].isin(images_downloaded)\n",
    "# s1_table['downloaded']\n",
    "s1_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22358181-5c37-4fb4-969d-1cd00ecd740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.data.listOperations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1920383-315c-4ce9-9f10-30be5b85ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample_names = []\n",
    "resample_names.append([1])\n",
    "resample_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9f2f09-95d1-4574-9422-cf3b4c95b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_table[s1_table['days_until_next'] < 0]\n",
    "# s1_table.loc[395:397]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7de490-bb94-4259-acb5-2917ff535c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import *\n",
    "from mizani.breaks import date_breaks\n",
    "from mizani.formatters import date_format\n",
    "\n",
    "(ggplot() +       # new\n",
    " geom_point(data = s1_table, mapping = aes('date', 'days_until_next', color = 'sample', shape = 'sample')) + \n",
    " scale_shape_manual(values = [\"|\", \"+\"]) +\n",
    " scale_x_datetime(breaks=date_breaks('2 years'), labels = date_format(\"%Y %b\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e411eaef-ac69-4af5-9109-2c31334c924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def DownloadS2pt(sample_pt_xy, loc_id, timeseries_dir_path, date_range):\n",
    "    \n",
    "sample_pt_name = 'pt_ts_' + str(loc_id)\n",
    "\n",
    "sample_pt = ee.Geometry.Point(sample_pt_xy)\n",
    "\n",
    "timeseries_dir_name = Path(timeseries_dir_path).parts[-1]\n",
    "s2_colname = 'pt_ts_loc_s2'\n",
    "s2_pt_filename = re.sub('loc_', 'loc_' + str(loc_id) +'_', s2_colname) #sample_pt_name + '_s2'\n",
    "s2_pt_filepath = os.path.join(timeseries_dir_path, s2_pt_filename + '.csv')\n",
    "\n",
    "# if os.path.exists(s2_pt_filepath):\n",
    "#     dummy = s2_pt_filepath\n",
    "#     print(s2_pt_filename + '.csv already exists')\n",
    "\n",
    "# else:\n",
    "\n",
    "s2_output_bands = ['B8','B4','B3','B2','clouds','cloudmask','shadows','probability']\n",
    "\n",
    "# params variable is used to pass  information to the cloud masking functions.\n",
    "# see help(add_cld_shadow_mask_func)\n",
    "s2params = {\n",
    "    'START_DATE' : date_range[0],\n",
    "    'END_DATE' : date_range[1],\n",
    "    'CLOUD_FILTER' : 50,\n",
    "    'CLD_PRB_THRESH' : 53, # 53 for Cauvery # 55 for Indus\n",
    "    'NIR_DRK_THRESH' : 0.2,\n",
    "    'CLD_PRJ_DIST' : 1,\n",
    "    'BUFFER' : 50\n",
    "}\n",
    "\n",
    "s2_clouds_ic = ees.get_s2_sr_cld_col(sample_pt, s2params) \\\n",
    "  .map(ees.add_cld_shadow_mask_func(s2params))\n",
    "\n",
    "# For some reason the reproject() works so that subsequent sampling returns the whole rectangular array\n",
    "# see https://stackoverflow.com/questions/64012752/gee-samplerectangle-returning-1x1-array\n",
    "# s2_clouds_im = s2_clouds_ic.mosaic().reproject(crs = ee.Projection('EPSG:4326'), scale=10) #.clip(hyd_watershed)\n",
    "\n",
    "# Get pixel timeseries\n",
    "s2_ts = rs.get_pixel_ts_allbands(\n",
    "    pts_fc = ee.FeatureCollection(sample_pt),\n",
    "    image_collection = s2_clouds_ic,\n",
    "    ic_property_id = 'system:index',\n",
    "    scale = 10) # for Landsat resolution\n",
    "# time_series_pd_load = geemap.ee_to_pandas(time_series_fc)\n",
    "\n",
    "task_s2 = ee.batch.Export.table.toDrive(\n",
    "    collection = s2_ts,\n",
    "    selectors = s2_output_bands + ['image_id'],\n",
    "    folder = timeseries_dir_name,\n",
    "    description = s2_pt_filename,\n",
    "    fileNamePrefix = s2_pt_filename)\n",
    "\n",
    "task_s2.start()\n",
    "\n",
    "\n",
    "print('Generating ' + s2_pt_filename + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e3c504-4e5d-472e-85d6-213e942aa958",
   "metadata": {},
   "source": [
    "## Function to download sentinel 2 and Landsat 8 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3888ecf5-899a-4458-b81f-10ab7620dbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DownloadS2pt(sample_pt_xy, loc_id, timeseries_dir_path, date_range):\n",
    "    \n",
    "    sample_pt_name = 'pt_ts_' + str(loc_id)\n",
    "    \n",
    "    sample_pt = ee.Geometry.Point(sample_pt_xy)\n",
    "    \n",
    "    timeseries_dir_name = Path(timeseries_dir_path).parts[-1]\n",
    "    s2_colname = 'pt_ts_loc_s2'\n",
    "    s2_pt_filename = re.sub('loc_', 'loc_' + str(loc_id) +'_', s2_colname) #sample_pt_name + '_s2'\n",
    "    s2_pt_filepath = os.path.join(timeseries_dir_path, s2_pt_filename + '.csv')\n",
    "    \n",
    "    if os.path.exists(s2_pt_filepath):\n",
    "        dummy = s2_pt_filepath\n",
    "        print(s2_pt_filename + '.csv already exists')\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        s2_output_bands = ['B8','B4','B3','B2','clouds','cloudmask','shadows','probability']\n",
    "        \n",
    "        # params variable is used to pass  information to the cloud masking functions.\n",
    "        # see help(add_cld_shadow_mask_func)\n",
    "        s2params = {\n",
    "            'START_DATE' : date_range[0],\n",
    "            'END_DATE' : date_range[1],\n",
    "            'CLOUD_FILTER' : 50,\n",
    "            'CLD_PRB_THRESH' : 53, # 53 for Cauvery # 55 for Indus\n",
    "            'NIR_DRK_THRESH' : 0.2,\n",
    "            'CLD_PRJ_DIST' : 1,\n",
    "            'BUFFER' : 50\n",
    "        }\n",
    "        \n",
    "        s2_clouds_ic = ees.get_s2_sr_cld_col(sample_pt, s2params) \\\n",
    "          .map(ees.add_cld_shadow_mask_func(s2params))\n",
    "        \n",
    "        # For some reason the reproject() works so that subsequent sampling returns the whole rectangular array\n",
    "        # see https://stackoverflow.com/questions/64012752/gee-samplerectangle-returning-1x1-array\n",
    "        # s2_clouds_im = s2_clouds_ic.mosaic().reproject(crs = ee.Projection('EPSG:4326'), scale=10) #.clip(hyd_watershed)\n",
    "        \n",
    "        # Get pixel timeseries\n",
    "        s2_ts = rs.get_pixel_ts_allbands(\n",
    "            pts_fc = ee.FeatureCollection(sample_pt),\n",
    "            image_collection = s2_clouds_ic,\n",
    "            ic_property_id = 'system:index',\n",
    "            scale = 10) # for Landsat resolution\n",
    "        # time_series_pd_load = geemap.ee_to_pandas(time_series_fc)\n",
    "            \n",
    "        task_s2 = ee.batch.Export.table.toDrive(\n",
    "            collection = s2_ts,\n",
    "            selectors = s2_output_bands + ['image_id'],\n",
    "            folder = timeseries_dir_name,\n",
    "            description = s2_pt_filename,\n",
    "            fileNamePrefix = s2_pt_filename)\n",
    "        \n",
    "        task_s2.start()\n",
    "        \n",
    "        \n",
    "        print('Generating ' + s2_pt_filename + '.csv')\n",
    "        \n",
    "def DownloadOLI8pt(sample_pt_xy, loc_id, timeseries_dir_path, date_range):\n",
    "    \n",
    "    sample_pt_name = 'pt_ts_' + str(loc_id)\n",
    "    \n",
    "    sample_pt = ee.Geometry.Point(sample_pt_xy)\n",
    "    \n",
    "    timeseries_dir_name = Path(timeseries_dir_path).parts[-1]\n",
    "    oli8_colname = 'pt_ts_loc_oli8'\n",
    "    oli8_pt_filename = re.sub('loc_', 'loc_' + str(loc_id) +'_', oli8_colname) #sample_pt_name + '_oli8'\n",
    "    oli8_pt_filepath = os.path.join(timeseries_dir_path, oli8_pt_filename + '.csv')\n",
    "    \n",
    "    if os.path.exists(oli8_pt_filepath):\n",
    "        print(oli8_pt_filepath + ' already exists')\n",
    "\n",
    "    else:\n",
    "        \n",
    "        oli8_output_bands = ['SR_B7','SR_B6','SR_B5','SR_B4','SR_B3','SR_B2','clouds','shadows','clouds_shadows']\n",
    "        oli8_ic = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
    "          .filterBounds(sample_pt) \\\n",
    "          .filterDate(date_range[0],date_range[1])\n",
    "          \n",
    "        get_qaband_clouds_shadows = rs.get_qaband_clouds_shadows_func(\n",
    "              qa_bandname = 'QA_PIXEL', \n",
    "              cloud_bit = 3, \n",
    "              shadow_bit = 4,\n",
    "              keep_orig_bands = True) \n",
    "        oli8_clouds_ic = (oli8_ic\n",
    "          .map(get_qaband_clouds_shadows))\n",
    "          # .map(lambda im: im.addBands(im.expression('im.clouds | im.clouds_shadows', {'im' : im}).rename('cloudmask'))))\n",
    "          \n",
    "        # Get oli8 pixel timeseries\n",
    "        oli8_ts = rs.get_pixel_ts_allbands(\n",
    "            pts_fc = ee.FeatureCollection(sample_pt),\n",
    "            image_collection = oli8_clouds_ic,\n",
    "            ic_property_id = 'system:index',\n",
    "            scale = 30) # for Landsat resolution\n",
    "        # time_series_pd_load = geemap.ee_to_pandas(time_series_fc)\n",
    "    \n",
    "        # oli8_output_bands = ['B8','B4','B3','B2','clouds','cloudmask','shadows','probability']\n",
    "        \n",
    "        \n",
    "        # For some reason the reproject() works so that subsequent sampling returns the whole rectangular array\n",
    "        # see https://stackoverflow.com/questions/64012752/gee-samplerectangle-returning-1x1-array\n",
    "        # oli8_clouds_im = oli8_clouds_ic.mosaic().reproject(crs = ee.Projection('EPSG:4326'), scale=10) #.clip(hyd_watershed)\n",
    "        \n",
    "            \n",
    "        task_oli8 = ee.batch.Export.table.toDrive(\n",
    "            collection = oli8_ts,\n",
    "            selectors = oli8_output_bands + ['image_id'],\n",
    "            folder = timeseries_dir_name,\n",
    "            description = oli8_pt_filename,\n",
    "            fileNamePrefix = oli8_pt_filename)\n",
    "        \n",
    "        task_oli8.start()\n",
    "                \n",
    "        # print('Generating ' + oli8_pt_filename + '.csv')\n",
    "        print('Generating ' + oli8_pt_filename + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf9ad27-c1af-4eb2-94c6-4d1f20e6aaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/gopal/Projects/ml/manclassify')\n",
    "from geemodules import rs\n",
    "from geemodules import eesentinel as ees\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674d0805-177a-4bc5-8ad8-b2e78563a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119c2078-59d1-4054-ba11-b2754200152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_dir_path = '/Users/gopal/Google Drive/_Research/Research projects/G_D/survey_pts/mig_survey_GEE'\n",
    "date_range = ['2012-06-01','2022-06-01']\n",
    "\n",
    "num_pts = survey_pts.shape[0]\n",
    "\n",
    "for i in np.arange(1062, num_pts):\n",
    "    sample_pt_xy = [survey_pts.lon.iloc[i],survey_pts.lat.iloc[i]]\n",
    "    loc_id = survey_pts.fid.iloc[i]\n",
    "    # print(f'{i+1} of {num_pts} pts, location id: {loc_id}')\n",
    "    # DownloadOLI8pt(sample_pt_xy, loc_id, timeseries_dir_path, date_range)\n",
    "    # DownloadS2pt(sample_pt_xy, loc_id, timeseries_dir_path, date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c37e41e-8370-49d7-bf29-1ecfc81612d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_string = re.sub('[\\s\\n\\.]', '', loc_id)\n",
    "# loc_id\n",
    "my_new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e5e6a2-1210-4e80-9464-625512701aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{1+1} of 4')\n",
    "1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manclassify",
   "language": "python",
   "name": "manclassify"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
